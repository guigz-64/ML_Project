{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "fic = open(\"data_ffnn_3classes.txt\", \"r\")\n",
    "data = np.loadtxt(fic)\n",
    "fic.close()\n",
    "\n",
    "#Convert the y array into a matrix of 3 columns\n",
    "def transfo_output(y):\n",
    "    a = np.zeros(3)\n",
    "    a[y] = 1\n",
    "    return a\n",
    "\n",
    "# Input data matrix\n",
    "training_input = [np.reshape(x, (1, 2)) for x in data[:,:2].astype(float)]\n",
    "\n",
    "  # Output matrix\n",
    "training_output = np.array([transfo_output(y) for y in np.array(data[:,2]).T.astype(int)])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "class Neural_Network1():\n",
    "    def init(self):\n",
    "        self.inputLayerSize=2\n",
    "        self.outputLayerSize=3\n",
    "        self.hiddenLayerSize=5\n",
    "        \n",
    "        self.w1=np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.w2=np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        #print(self.w1)\n",
    "        #print(self.w2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def forward(self, X):\n",
    "         \n",
    "        self.z2 = np.dot(X,self.w1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2,self.w2)\n",
    "        yHat = self.sigmoid(self.z3)\n",
    "        return yHat\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        err=0\n",
    "\n",
    "        for x, y in zip(training_input, training_output): \n",
    "            yHat = NN.forward(x)\n",
    "                \n",
    "            #calculation of the error \n",
    "            #very high error contrary of the one we got for the back propagation \n",
    "            e = 1 / 2 * np.sum((y - yHat)**2)\n",
    "            print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45459207263708634\n",
      "0.45662824543906166\n",
      "0.47215481153010286\n",
      "0.4665476956353064\n",
      "0.47145802394875463\n",
      "0.47890352359926336\n",
      "0.47251743404670177\n",
      "0.48194183469467544\n",
      "0.46684961801552927\n",
      "0.46573163735009904\n",
      "0.47478108399119223\n",
      "0.46607302412400775\n",
      "0.4504201355434584\n",
      "0.45937018587578793\n",
      "0.46148610445168076\n",
      "0.47394536293001355\n",
      "0.47811880917927685\n",
      "0.47898245014306307\n",
      "0.47359156341449093\n",
      "0.46670944880377574\n",
      "0.6390017645355602\n",
      "0.6619114803539784\n",
      "0.6601543123361845\n",
      "0.6759557526657187\n",
      "0.6763908907143887\n",
      "0.6983477798692775\n",
      "0.708468130927336\n",
      "0.6917403076948309\n",
      "0.6882796280212368\n",
      "0.6632729974437239\n",
      "0.6663405403217362\n",
      "0.6213954058148177\n",
      "0.656638870832482\n",
      "0.6377103289680907\n",
      "0.6383901388844151\n",
      "0.6486883382845741\n",
      "0.6424754633017955\n",
      "0.5999763330331739\n",
      "0.6132782557562073\n",
      "0.5878249557883783\n",
      "0.5996460605933599\n",
      "0.6182779758958084\n",
      "0.623159031842417\n",
      "0.6785658737752426\n",
      "0.6838348134628571\n",
      "0.7045121821387481\n",
      "0.6833080788039019\n",
      "0.6862698286731961\n",
      "0.5945567721183895\n",
      "0.5862657883730302\n",
      "0.404339872802304\n",
      "0.10734444996468982\n",
      "0.11429776420939605\n",
      "0.10861448889795519\n",
      "0.12097973716690126\n",
      "0.11599223717653515\n",
      "0.1138973973294323\n",
      "0.10864734958235933\n",
      "0.10969013943024555\n",
      "0.11803413008445471\n",
      "0.10778506994886672\n",
      "0.11859547528682576\n",
      "0.1181780113246135\n",
      "0.1116479625909714\n",
      "0.10463081173191416\n",
      "0.12317037929481826\n",
      "0.1230296972984483\n",
      "0.12057992438369362\n",
      "0.12078043350472925\n",
      "0.1236236904786979\n",
      "0.11884210845824225\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "NN.init()\n",
    "\n",
    "NN.train(training_input,training_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "class Neural_Network2():\n",
    "    \n",
    "    def init(self):\n",
    "        #init V and W\n",
    "        self.inputLayerSize=2\n",
    "        self.outputLayerSize=3\n",
    "        self.hiddenLayerSize=5\n",
    "        \n",
    "        self.w1=np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.w2=np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "    \n",
    "    #use of expit to reduce the flow of data due to input values\n",
    "    def sigmoid(self, z):\n",
    "        return expit(z)\n",
    "    \n",
    "    def sigmoidPrime(self,x):\n",
    "        return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z2 = np.dot(X,self.w1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2,self.w2)\n",
    "        yHat = self.sigmoid(self.z3)\n",
    "        return yHat\n",
    "    \n",
    "    def train(self,X,y,iteration,alpha):\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            err=0\n",
    "            result=[]\n",
    "            \n",
    "            for x, y in zip(training_input, training_output):\n",
    "                #for each value of training input we use the forward algorithm\n",
    "                z2 = np.dot(x,self.w1)\n",
    "                a2 = self.sigmoid(z2)\n",
    "                z3 = np.dot(a2,self.w2)\n",
    "                yHat = self.sigmoid(z3)                 \n",
    "                \n",
    "                #calculation of the error \n",
    "                e = 1 / 2 * np.sum((y - yHat)**2)\n",
    "                \n",
    "                #calculation of the derivative error \n",
    "                delta3 = np.multiply((yHat-y),self.sigmoidPrime(z3))\n",
    "                dEdW2 = np.dot(a2.T,delta3)\n",
    "                delta2 = np.dot(delta3,self.w2.T)*self.sigmoidPrime(z2)\n",
    "                dEdW1 = np.dot(x.T, delta2)\n",
    "                \n",
    "                #calculation of a better V and W through the iterations\n",
    "                self.w1=self.w1 - alpha*dEdW1\n",
    "                self.w2=self.w2 - alpha*dEdW2\n",
    "                \n",
    "                #we stock the better values of yHat \n",
    "                if(i==999):\n",
    "                    result.append(yHat)\n",
    "        \n",
    "            #2\n",
    "            plt.scatter(i, e)\n",
    "        \n",
    "        print(\"The best error that we find is :\",e)\n",
    "        \n",
    "        #3\n",
    "        print(\"v\")\n",
    "        print(self.w1)\n",
    "        print(\"w\")\n",
    "        print(self.w2)\n",
    "        plt.show()\n",
    "        \n",
    "        return result\n",
    "       \n",
    "    #4    \n",
    "    def convert_1(self,x):\n",
    "            if x[0][0] > 0.66:\n",
    "                return 0\n",
    "            if x[0][1] > 0.66:\n",
    "                return 1\n",
    "            return 2\n",
    "    \n",
    "    def convert_2(self,x):\n",
    "        if x[0] > 0.66:\n",
    "            return 0\n",
    "        if x[1] > 0.66:\n",
    "            return 1\n",
    "        return 2\n",
    "        \n",
    "    #we only get an average of 60 successes over 71. We don't know where the error comes from but most of them appears for the output y=1\n",
    "    def verify(self,result):\n",
    "        sucess = 0\n",
    "        for i in range(0, len(result)):\n",
    "            if NN2.convert_1(result[i]) == NN2.convert_1([training_output[i]]):\n",
    "                sucess+=1\n",
    "        print(\"nombre succès\")\n",
    "        print(sucess)\n",
    "    \n",
    "    #5\n",
    "    def test(self, x1, x2):\n",
    "        tmp = np.array([x1, x2])\n",
    "        return self.forward(tmp)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best error that we find is : 0.00019380985370717705\n",
      "v\n",
      "[[ 1.38990856 -0.12003344  4.55231321  0.18502427  0.14688721]\n",
      " [ 2.20327692  0.48814217 -7.1373729  -0.54155648 -0.50974025]]\n",
      "w\n",
      "[[  2.94721831  -3.14447216  -3.70779033]\n",
      " [ -5.05174783   5.46845889  -1.78374258]\n",
      " [-10.25859057  -3.26397903   7.54947942]\n",
      " [  6.4758865   -7.30927463   0.59601294]\n",
      " [  5.73447845  -5.99343622   2.44871797]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre succès\n",
      "61\n",
      "[0.96986504 0.0214193  0.02035692]  =  0\n",
      "[0.76501363 0.22275758 0.01016778]  =  0\n",
      "[1.64781545e-02 4.79486659e-05 9.86955738e-01]  =  2\n"
     ]
    }
   ],
   "source": [
    "NN2=Neural_Network2()\n",
    "NN2.init()\n",
    "result=NN2.train(training_input,training_output,1000,0.1)\n",
    "NN2.verify(result)\n",
    "\n",
    "tmp = NN2.test(2, 2)\n",
    "print(tmp, \" = \", str(NN2.convert_2(tmp)))\n",
    "#we got an error here\n",
    "#it confirms what we said before which is that we got an error when y=1\n",
    "tmp = NN2.test(4, 4)\n",
    "print(tmp, \" = \", str(NN2.convert_2(tmp)))\n",
    "tmp = NN2.test(4.5, 1.5)\n",
    "print(tmp, \" = \", str(NN2.convert_2(tmp)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Boston_Housing_Pm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
